{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis project notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uncomment and run the cell below to automatically install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import utils\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load comments from a json file and see how many there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local file <comments_4DCbZJh-Gk4.json>\n",
      "['Outstanding!', 'my lord i imagine a war space i love this emg videos john browne are the best ever   ...ever suppppport  djent\\nim from argentina say love metal instrumental', \"1:31 that switch up is fucking timeless. I've known this song for about 5 years now and it still never gets old.\", 'And yet we still search for proof of alien life ü§∑üèª\\u200d‚ôÇÔ∏è', 'After almost 7 years this playthrough still brings tears to my eyes. So good and hope to see Monuments live again soon!', 'Djesus Christ', 'Masterpiece!!', 'god DAMN that part beginning at 1:58 is SOOO fucking good like holy FUCK man', 'All finger breaker chords. All the time.', 'Bruh']\n",
      "There are 100 comments in this dataset\n"
     ]
    }
   ],
   "source": [
    "from get_video import load_comments\n",
    "\n",
    "comments = load_comments(\"comments_4DCbZJh-Gk4.json\")\n",
    "print(comments[:10])\n",
    "print(f\"There are {len(comments)} comments in this dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might take some time depending on the size of our dataset, so let's define some checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = {int(len(comments) * perc): perc * 100 for perc in [0.25, 0.5, 0.75, 0.9, 1]} # shamelessly stolen from Computational Linguistics Notebook 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can start analyzing them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze the comments with BERT first, and save the results to a list. This is due to the fact that the BERT classifier pipeline works better when given a list of comments rather than a single comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_scores = utils.bert_classifier(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we analyze the comments iteratively using Vader and Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25% of the comments have been analyzed\n",
      "Time elapsed: 16.59 seconds\n",
      "50% of the comments have been analyzed\n",
      "Time elapsed: 31.92 seconds\n",
      "75% of the comments have been analyzed\n",
      "Time elapsed: 47.19 seconds\n",
      "90% of the comments have been analyzed\n",
      "Time elapsed: 56.23 seconds\n",
      "100% of the comments have been analyzed\n",
      "Time elapsed: 62.50 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i, comment in enumerate(comments):\n",
    "        current_time = time.time()\n",
    "        elapsed_time = current_time - start_time\n",
    "\n",
    "        lang = utils.detect_language(comment)\n",
    "\n",
    "        # Vader\n",
    "        vader_score = utils.vader_classifier(comment)\n",
    "\n",
    "        # TextBlob - Polarity is a a float between -1 and 1 where -1 is negative and 1 is positive\n",
    "        blob_score = utils.textblob_classifier(comment)\n",
    "\n",
    "        df_dict = {\n",
    "            \"Comment\": comment,\n",
    "            \"Language\": lang,\n",
    "            \"Vader score\": vader_score,\n",
    "            \"Textblob score\": blob_score,\n",
    "        }\n",
    "\n",
    "        df_list.append(df_dict)\n",
    "\n",
    "        if i + 1 in checkpoints:\n",
    "            print(f\"{checkpoints[i+1] :.0f}% of the comments have been analyzed\\nTime elapsed: {elapsed_time :.2f} seconds\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should merge the results of both analyses into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_list)\n",
    "series_bert = pd.Series(bert_scores)\n",
    "\n",
    "df['BERT score'] = series_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the dataframe. Start by looking at the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Language</th>\n",
       "      <th>Vader score</th>\n",
       "      <th>Textblob score</th>\n",
       "      <th>BERT score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outstanding!</td>\n",
       "      <td>de</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.896599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my lord i imagine a war space i love this emg ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.894711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:31 that switch up is fucking timeless. I've ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.551378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And yet we still search for proof of alien lif...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.367565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After almost 7 years this playthrough still br...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>0.435227</td>\n",
       "      <td>0.736152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Djesus Christ</td>\n",
       "      <td>et</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Masterpiece!!</td>\n",
       "      <td>ro</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>god DAMN that part beginning at 1:58 is SOOO f...</td>\n",
       "      <td>en</td>\n",
       "      <td>-0.1518</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-0.496737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>All finger breaker chords. All the time.</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bruh</td>\n",
       "      <td>id</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.386926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Language  Vader score  \\\n",
       "0                                       Outstanding!       de       0.6476   \n",
       "1  my lord i imagine a war space i love this emg ...       en       0.8658   \n",
       "2  1:31 that switch up is fucking timeless. I've ...       en       0.0000   \n",
       "3  And yet we still search for proof of alien lif...       en       0.0000   \n",
       "4  After almost 7 years this playthrough still br...       en       0.7428   \n",
       "5                                      Djesus Christ       et       0.0000   \n",
       "6                                      Masterpiece!!       ro       0.6892   \n",
       "7  god DAMN that part beginning at 1:58 is SOOO f...       en      -0.1518   \n",
       "8           All finger breaker chords. All the time.       en       0.0000   \n",
       "9                                               Bruh       id       0.0000   \n",
       "\n",
       "   Textblob score  BERT score  \n",
       "0        0.625000    0.896599  \n",
       "1        0.666667    0.894711  \n",
       "2       -0.250000   -0.551378  \n",
       "3       -0.250000    0.367565  \n",
       "4        0.435227    0.736152  \n",
       "5        0.000000    0.272853  \n",
       "6        0.000000    0.879835  \n",
       "7        0.150000   -0.496737  \n",
       "8        0.000000    0.759309  \n",
       "9        0.000000   -0.386926  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's check the stats for our numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Vader score  Textblob score  BERT score\n",
      "count   100.000000      100.000000  100.000000\n",
      "mean      0.245066        0.177426    0.246427\n",
      "std       0.460005        0.421838    0.564940\n",
      "min      -0.726200       -1.000000   -0.967942\n",
      "25%       0.000000        0.000000   -0.289669\n",
      "50%       0.080000        0.129018    0.385416\n",
      "75%       0.682900        0.482924    0.723057\n",
      "max       0.957100        1.000000    0.951091\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models seem to be predicting very similarly, but we should still check mathematically using Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Vader score  Textblob score  BERT score\n",
      "Vader score        1.000000        0.667741    0.465176\n",
      "Textblob score     0.667741        1.000000    0.561260\n",
      "BERT score         0.465176        0.561260    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an idea of what our analysis is going to look like. However, one video is not enough. Let's build a bigger dataset using the top 100 most searched terms on YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Search Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bts</td>\n",
       "      <td>16,723,304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pewdiepie</td>\n",
       "      <td>16,495,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>asmr</td>\n",
       "      <td>14,655,088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>billie eilish</td>\n",
       "      <td>13,801,247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>baby shark</td>\n",
       "      <td>12,110,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>old town road</td>\n",
       "      <td>10,456,524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>music</td>\n",
       "      <td>10,232,134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>badabun</td>\n",
       "      <td>10,188,997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>blackpink</td>\n",
       "      <td>9,580,131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>fortnite</td>\n",
       "      <td>9,117,342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    #        Keyword Search Volume\n",
       "0   1            bts    16,723,304\n",
       "1   2      pewdiepie    16,495,659\n",
       "2   3           asmr    14,655,088\n",
       "3   4  billie eilish    13,801,247\n",
       "4   5     baby shark    12,110,100\n",
       "5   6  old town road    10,456,524\n",
       "6   7          music    10,232,134\n",
       "7   8        badabun    10,188,997\n",
       "8   9      blackpink     9,580,131\n",
       "9  10       fortnite     9,117,342"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = pd.read_csv('search.tsv', sep='\\t') #obtained from https://ahrefs.com/blog/top-youtube-searches/\n",
    "terms.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these search terms to get YouTube video links which we can then use to gather comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_video import get_videos\n",
    "half = terms.head(50)\n",
    "search_terms = half[\"Keyword\"]\n",
    "urls = []\n",
    "\n",
    "for term in search_terms:\n",
    "    urls.append(get_videos(term))\n",
    "\n",
    "links = list(set(item for sublist in urls for item in sublist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911 links have been collected\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(links)} links have been collected\")\n",
    "\n",
    "with open(\"videos__.json\", \"w\") as f:\n",
    "    json.dump(links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a1d14109658dfc9fc37f7252e7fc4fbbe9f7c5bac9b61d43e9e98742e708099"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
