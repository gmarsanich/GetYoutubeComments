{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis project notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uncomment and run the cell below to automatically install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "import pandas as pd\n",
    "import utils\n",
    "import langdetect as ld\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the real analysis is going to take a long time to complete, we'll start with a toy example which takes about a minute. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load comments from a json file and see how many there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local file <comments_4DCbZJh-Gk4__.json>\n",
      "There are 100 comments in this dataset\n",
      "['Outstanding!', 'my lord i imagine a war space i love this emg videos john browne are the best ever   ...ever suppppport  djent\\nim from argentina say love metal instrumental', \"1:31 that switch up is fucking timeless. I've known this song for about 5 years now and it still never gets old.\", 'And yet we still search for proof of alien life ü§∑üèª\\u200d‚ôÇÔ∏è', 'After almost 7 years this playthrough still brings tears to my eyes. So good and hope to see Monuments live again soon!', 'Djesus Christ', 'Masterpiece!!', 'god DAMN that part beginning at 1:58 is SOOO fucking good like holy FUCK man', 'All finger breaker chords. All the time.', 'Bruh']\n"
     ]
    }
   ],
   "source": [
    "from get_video import load_comments\n",
    "\n",
    "comments = load_comments(\"comments_4DCbZJh-Gk4__.json\")\n",
    "print(f\"There are {len(comments)} comments in this dataset\")\n",
    "print(comments[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can start analyzing them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze the comments with BERT first, and save the results to a list. This is due to the fact that the BERT classifier pipeline works better when given a list of comments rather than a single comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_scores = utils.bert_classifier(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we analyze the comments using Vader and Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "scores_list = []\n",
    "\n",
    "with Pool() as p:\n",
    "    analysis1 = p.map(utils.vader_classifier, comments)\n",
    "    analysis2 = p.map(utils.textblob_classifier, comments)\n",
    "    scores_list.append(analysis1)\n",
    "    scores_list.append(analysis2)\n",
    "\n",
    "for comment, v_score, t_score in zip(comments, scores_list[0], scores_list[1]):\n",
    "    df_dict = {\n",
    "        \"Comment\": comment,\n",
    "        \"Vader score\": v_score,\n",
    "        \"TextBlob score\": t_score,\n",
    "    }\n",
    "    df_list.append(df_dict)\n",
    "\n",
    "df = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should merge the results of both analyses into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_list)\n",
    "series_bert = pd.Series(bert_scores)\n",
    "\n",
    "df['BERT score'] = series_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the dataframe. Start by looking at the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Vader score</th>\n",
       "      <th>TextBlob score</th>\n",
       "      <th>BERT score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outstanding!</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.896599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my lord i imagine a war space i love this emg ...</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.894711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:31 that switch up is fucking timeless. I've ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.551378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And yet we still search for proof of alien lif...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.367565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After almost 7 years this playthrough still br...</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>0.435227</td>\n",
       "      <td>0.736152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Djesus Christ</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Masterpiece!!</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>god DAMN that part beginning at 1:58 is SOOO f...</td>\n",
       "      <td>-0.1518</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-0.496737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>All finger breaker chords. All the time.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bruh</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.386926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Vader score  \\\n",
       "0                                       Outstanding!       0.6476   \n",
       "1  my lord i imagine a war space i love this emg ...       0.8658   \n",
       "2  1:31 that switch up is fucking timeless. I've ...       0.0000   \n",
       "3  And yet we still search for proof of alien lif...       0.0000   \n",
       "4  After almost 7 years this playthrough still br...       0.7428   \n",
       "5                                      Djesus Christ       0.0000   \n",
       "6                                      Masterpiece!!       0.6892   \n",
       "7  god DAMN that part beginning at 1:58 is SOOO f...      -0.1518   \n",
       "8           All finger breaker chords. All the time.       0.0000   \n",
       "9                                               Bruh       0.0000   \n",
       "\n",
       "   TextBlob score  BERT score  \n",
       "0        0.625000    0.896599  \n",
       "1        0.666667    0.894711  \n",
       "2       -0.250000   -0.551378  \n",
       "3       -0.250000    0.367565  \n",
       "4        0.435227    0.736152  \n",
       "5        0.000000    0.272853  \n",
       "6        0.000000    0.879835  \n",
       "7        0.150000   -0.496737  \n",
       "8        0.000000    0.759309  \n",
       "9        0.000000   -0.386926  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores are useful for computation, but not so much for legibility. It would be good to have labels so we know what the scores mean exactly. The Vader team has ranges defined on their GitHub repository, so assigning labels is going to be very easy. BERT returns a label, but it's not formatted in a way that we like. TextBlob doesn't return labels at all, and ideal ranges are not defined in the documentation. Let's add some labels now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_labels = utils.generate_labels(df[\"Vader score\"], \"vader\")\n",
    "blob_labels = utils.generate_labels(df[\"TextBlob score\"], \"blob\")\n",
    "bert_labels = utils.generate_labels(df[\"BERT score\"], \"bert\")\n",
    "\n",
    "vader_labels_series = pd.Series(vader_labels)\n",
    "blob_labels_series = pd.Series(blob_labels)\n",
    "bert_labels_series = pd.Series(bert_labels)\n",
    "\n",
    "df['Vader label'] = vader_labels_series\n",
    "df['TextBlob label'] = blob_labels_series\n",
    "df['BERT label'] = bert_labels_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rearrange the columns and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Vader score</th>\n",
       "      <th>Vader label</th>\n",
       "      <th>TextBlob score</th>\n",
       "      <th>TextBlob label</th>\n",
       "      <th>BERT score</th>\n",
       "      <th>BERT label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outstanding!</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.896599</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my lord i imagine a war space i love this emg ...</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.894711</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:31 that switch up is fucking timeless. I've ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.551378</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And yet we still search for proof of alien lif...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.367565</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After almost 7 years this playthrough still br...</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.435227</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.736152</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Djesus Christ</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Netural</td>\n",
       "      <td>0.272853</td>\n",
       "      <td>Netural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Masterpiece!!</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Netural</td>\n",
       "      <td>0.879835</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>god DAMN that part beginning at 1:58 is SOOO f...</td>\n",
       "      <td>-0.1518</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>Netural</td>\n",
       "      <td>-0.496737</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>All finger breaker chords. All the time.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Netural</td>\n",
       "      <td>0.759309</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bruh</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Netural</td>\n",
       "      <td>-0.386926</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Vader score Vader label  \\\n",
       "0                                       Outstanding!       0.6476    Positive   \n",
       "1  my lord i imagine a war space i love this emg ...       0.8658    Positive   \n",
       "2  1:31 that switch up is fucking timeless. I've ...       0.0000     Neutral   \n",
       "3  And yet we still search for proof of alien lif...       0.0000     Neutral   \n",
       "4  After almost 7 years this playthrough still br...       0.7428    Positive   \n",
       "5                                      Djesus Christ       0.0000     Neutral   \n",
       "6                                      Masterpiece!!       0.6892    Positive   \n",
       "7  god DAMN that part beginning at 1:58 is SOOO f...      -0.1518    Negative   \n",
       "8           All finger breaker chords. All the time.       0.0000     Neutral   \n",
       "9                                               Bruh       0.0000     Neutral   \n",
       "\n",
       "   TextBlob score TextBlob label  BERT score BERT label  \n",
       "0        0.625000       Positive    0.896599   Positive  \n",
       "1        0.666667       Positive    0.894711   Positive  \n",
       "2       -0.250000       Negative   -0.551378   Negative  \n",
       "3       -0.250000       Negative    0.367565   Positive  \n",
       "4        0.435227       Positive    0.736152   Positive  \n",
       "5        0.000000        Netural    0.272853    Netural  \n",
       "6        0.000000        Netural    0.879835   Positive  \n",
       "7        0.150000        Netural   -0.496737   Negative  \n",
       "8        0.000000        Netural    0.759309   Positive  \n",
       "9        0.000000        Netural   -0.386926   Negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"Comment\",\"Vader score\", \"Vader label\", \"TextBlob score\", \"TextBlob label\", \"BERT score\", \"BERT label\"]]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's check the stats for our numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Vader score  TextBlob score  BERT score\n",
      "count   100.000000      100.000000  100.000000\n",
      "mean      0.245066        0.177426    0.246427\n",
      "std       0.460005        0.421838    0.564940\n",
      "min      -0.726200       -1.000000   -0.967942\n",
      "25%       0.000000        0.000000   -0.289669\n",
      "50%       0.080000        0.129018    0.385416\n",
      "75%       0.682900        0.482924    0.723057\n",
      "max       0.957100        1.000000    0.951091\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models seem to be predicting very similarly, but we should still check mathematically using Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Vader score  TextBlob score  BERT score\n",
      "Vader score        1.000000        0.667741    0.465176\n",
      "TextBlob score     0.667741        1.000000    0.561260\n",
      "BERT score         0.465176        0.561260    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an idea of what our analysis is going to look like. However, one video is not enough. Let's build a bigger dataset using the top 100 most searched terms on YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Search Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bts</td>\n",
       "      <td>16,723,304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pewdiepie</td>\n",
       "      <td>16,495,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>asmr</td>\n",
       "      <td>14,655,088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>billie eilish</td>\n",
       "      <td>13,801,247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>baby shark</td>\n",
       "      <td>12,110,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>old town road</td>\n",
       "      <td>10,456,524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>music</td>\n",
       "      <td>10,232,134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>badabun</td>\n",
       "      <td>10,188,997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>blackpink</td>\n",
       "      <td>9,580,131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>fortnite</td>\n",
       "      <td>9,117,342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    #        Keyword Search Volume\n",
       "0   1            bts    16,723,304\n",
       "1   2      pewdiepie    16,495,659\n",
       "2   3           asmr    14,655,088\n",
       "3   4  billie eilish    13,801,247\n",
       "4   5     baby shark    12,110,100\n",
       "5   6  old town road    10,456,524\n",
       "6   7          music    10,232,134\n",
       "7   8        badabun    10,188,997\n",
       "8   9      blackpink     9,580,131\n",
       "9  10       fortnite     9,117,342"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = pd.read_csv('search.tsv', sep='\\t') # obtained from https://ahrefs.com/blog/top-youtube-searches/\n",
    "terms.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these search terms to get YouTube video links which we can then use to gather comments. To save some time (and some precious API quota) we'll use the top 50 searched terms\n",
    "\n",
    "This cell should not be run more than once a month. To make sure you never have to run it again, save the output to a file and load it for subsequent runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_video import get_videos\n",
    "half = terms.head(50)\n",
    "search_terms = half[\"Keyword\"]\n",
    "urls = []\n",
    "\n",
    "for term in search_terms:\n",
    "    urls.append(get_videos(term))\n",
    "\n",
    "links = list(set(item for sublist in urls for item in sublist))\n",
    "\n",
    "with open(\"videos__.json\", \"w\") as f:\n",
    "    json.dump(links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains <911> links\n"
     ]
    }
   ],
   "source": [
    "with open(\"videos__.json\", \"r\") as f:\n",
    "    links = json.load(f)\n",
    "\n",
    "print(f\"This file contains <{len(links)}> links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lot of links (and therefore a lot of data). However, taking into account the rate of analysis and the amount of comments per video, we realize that it's going to take a lot of time: many of these videos have around 20,000 comments minimum. Knowing that it takes this program around 30 seconds to analyze 100 comments, analyzing all comments would take days. \n",
    "\n",
    "Instead of waiting for 9 days, we can make a compromise: we can take a sample of 500 comments per video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our list of links, we can start collecting data. Let's do the fast part first: collecting the like/dislike ratio and saving it somewhere convenient for later. \n",
    "\n",
    "As before, this cell should ideally be run once only as it takes a bit of time - around 15 minutes. If the notebook needs to be restarted, you should load the csv file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_video import get_likes\n",
    "start_time = time.time()\n",
    "\n",
    "with open(\"videos__.json\", \"r\") as f:\n",
    "    links = json.load(f)\n",
    "df_list = []\n",
    "\n",
    "checkpoints = {int(len(links) * perc): perc * 100 for perc in [0.25, 0.5, 0.75, 0.9, 1]} # same as before\n",
    "\n",
    "for i, link in enumerate(links):\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    data = get_likes(link)\n",
    "    df_list.append(data)\n",
    "    time.sleep(1) # otherwise we will get an HTTP error\n",
    "    if i + 1 in checkpoints:\n",
    "            print(f\"{checkpoints[i+1] :.0f}% of the videos have been analyzed\\nTime elapsed: {elapsed_time :.2f} seconds\")  \n",
    "     \n",
    "df = pd.DataFrame(df_list)\n",
    "utils.save_analysis(df, \"top50_ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=feLcMaiClOw</td>\n",
       "      <td>312761</td>\n",
       "      <td>19093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com/watch?v=tASwv-tkMlc</td>\n",
       "      <td>35026</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.youtube.com/watch?v=3U2dNKBM28o</td>\n",
       "      <td>126427</td>\n",
       "      <td>6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.youtube.com/watch?v=1cPDfXU95Xw</td>\n",
       "      <td>23783</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.youtube.com/watch?v=pptIU_ZLlOo</td>\n",
       "      <td>4600</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.youtube.com/watch?v=ClQ-ymoXJZc</td>\n",
       "      <td>1079676</td>\n",
       "      <td>8874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.youtube.com/watch?v=8EJ3zbKTWQ8</td>\n",
       "      <td>11371069</td>\n",
       "      <td>1420624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.youtube.com/watch?v=t99KH0TR-J4</td>\n",
       "      <td>1435738</td>\n",
       "      <td>33092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.youtube.com/watch?v=DovdIspaqmw</td>\n",
       "      <td>146007</td>\n",
       "      <td>5324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.youtube.com/watch?v=DQQRjFzB8gY</td>\n",
       "      <td>870202</td>\n",
       "      <td>49922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           URL     likes  dislikes\n",
       "0  https://www.youtube.com/watch?v=feLcMaiClOw    312761     19093\n",
       "1  https://www.youtube.com/watch?v=tASwv-tkMlc     35026       165\n",
       "2  https://www.youtube.com/watch?v=3U2dNKBM28o    126427      6010\n",
       "3  https://www.youtube.com/watch?v=1cPDfXU95Xw     23783        18\n",
       "4  https://www.youtube.com/watch?v=pptIU_ZLlOo      4600         7\n",
       "5  https://www.youtube.com/watch?v=ClQ-ymoXJZc   1079676      8874\n",
       "6  https://www.youtube.com/watch?v=8EJ3zbKTWQ8  11371069   1420624\n",
       "7  https://www.youtube.com/watch?v=t99KH0TR-J4   1435738     33092\n",
       "8  https://www.youtube.com/watch?v=DovdIspaqmw    146007      5324\n",
       "9  https://www.youtube.com/watch?v=DQQRjFzB8gY    870202     49922"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes_df = pd.read_csv(\"analysis_top50_ratio.csv\", index_col = 0)\n",
    "likes_df = likes_df.reset_index()\n",
    "likes_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good data, but it is not complete. We are still missing the ratio of likes to dislikes. Let's compute that now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      16.381\n",
       "1     212.279\n",
       "2      21.036\n",
       "3    1321.278\n",
       "4     657.143\n",
       "5     121.667\n",
       "6       8.004\n",
       "7      43.386\n",
       "8      27.424\n",
       "9      17.431\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes, dislikes = likes_df['likes'], likes_df['dislikes']\n",
    "\n",
    "ratios = []\n",
    "\n",
    "for like, dislike in zip(likes, dislikes):\n",
    "    if like == 0 or dislike == 0:\n",
    "        ratio = 0\n",
    "        ratios.append(ratio)\n",
    "    else:\n",
    "        ratio = round(like / dislike, 3)\n",
    "        ratios.append(ratio)\n",
    "\n",
    "ratios = pd.Series(ratios)\n",
    "ratios.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add this list to our dataframe and compute the mean ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean like/dislike ratio = 123.55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=feLcMaiClOw</td>\n",
       "      <td>312761</td>\n",
       "      <td>19093</td>\n",
       "      <td>16.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com/watch?v=tASwv-tkMlc</td>\n",
       "      <td>35026</td>\n",
       "      <td>165</td>\n",
       "      <td>212.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.youtube.com/watch?v=3U2dNKBM28o</td>\n",
       "      <td>126427</td>\n",
       "      <td>6010</td>\n",
       "      <td>21.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.youtube.com/watch?v=1cPDfXU95Xw</td>\n",
       "      <td>23783</td>\n",
       "      <td>18</td>\n",
       "      <td>1321.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.youtube.com/watch?v=pptIU_ZLlOo</td>\n",
       "      <td>4600</td>\n",
       "      <td>7</td>\n",
       "      <td>657.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.youtube.com/watch?v=ClQ-ymoXJZc</td>\n",
       "      <td>1079676</td>\n",
       "      <td>8874</td>\n",
       "      <td>121.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.youtube.com/watch?v=8EJ3zbKTWQ8</td>\n",
       "      <td>11371069</td>\n",
       "      <td>1420624</td>\n",
       "      <td>8.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.youtube.com/watch?v=t99KH0TR-J4</td>\n",
       "      <td>1435738</td>\n",
       "      <td>33092</td>\n",
       "      <td>43.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.youtube.com/watch?v=DovdIspaqmw</td>\n",
       "      <td>146007</td>\n",
       "      <td>5324</td>\n",
       "      <td>27.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.youtube.com/watch?v=DQQRjFzB8gY</td>\n",
       "      <td>870202</td>\n",
       "      <td>49922</td>\n",
       "      <td>17.431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           URL     likes  dislikes     ratio\n",
       "0  https://www.youtube.com/watch?v=feLcMaiClOw    312761     19093    16.381\n",
       "1  https://www.youtube.com/watch?v=tASwv-tkMlc     35026       165   212.279\n",
       "2  https://www.youtube.com/watch?v=3U2dNKBM28o    126427      6010    21.036\n",
       "3  https://www.youtube.com/watch?v=1cPDfXU95Xw     23783        18  1321.278\n",
       "4  https://www.youtube.com/watch?v=pptIU_ZLlOo      4600         7   657.143\n",
       "5  https://www.youtube.com/watch?v=ClQ-ymoXJZc   1079676      8874   121.667\n",
       "6  https://www.youtube.com/watch?v=8EJ3zbKTWQ8  11371069   1420624     8.004\n",
       "7  https://www.youtube.com/watch?v=t99KH0TR-J4   1435738     33092    43.386\n",
       "8  https://www.youtube.com/watch?v=DovdIspaqmw    146007      5324    27.424\n",
       "9  https://www.youtube.com/watch?v=DQQRjFzB8gY    870202     49922    17.431"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes_df['ratio'] = ratios.astype('float64') \n",
    "mean_ratio = ratios.mean()\n",
    "print(f\"Mean like/dislike ratio = {mean_ratio :.2f}\")\n",
    "likes_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the data in this dataframe as the baseline for the sentiment analysis.\n",
    "\n",
    "This process is going to take a long time to complete, even with multiprocessing. \n",
    "\n",
    "Let's start by collecting the comments.\n",
    "The results will be saved to a file, so there's no need to run this cell more than once if everything goes well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_video import get_id, get_comments\n",
    "import googleapiclient.discovery\n",
    "\n",
    "urls = list(likes_df[\"URL\"])\n",
    "\n",
    "target_dir = f\"{os.getcwd()}/Data\"\n",
    "if not os.path.exists(target_dir):\n",
    "    os.mkdir(target_dir)\n",
    "\n",
    "for url in urls:\n",
    "    video_id = get_id(url)\n",
    "    try:\n",
    "        comments = get_comments(url)\n",
    "    except googleapiclient.errors.HttpError:\n",
    "        continue\n",
    "    utils.move_dir(f\"comments_{video_id}.json\", target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem: some of the files have very few comments, and we need at least 500. So, we will have to remove all files with less than 500 comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = f\"{os.getcwd()}\\\\Data\"\n",
    "trash = f\"{os.getcwd()}\\\\Trash\"\n",
    "\n",
    "checkpoints = {int(len(links) * perc): perc * 100 for perc in [0.25, 0.5, 0.75, 0.9, 1]} # same as before\n",
    "\n",
    "if not os.path.exists(trash):\n",
    "    os.mkdir(trash)\n",
    "\n",
    "data = os.listdir(target_dir)\n",
    "\n",
    "start =  time.time()\n",
    "\n",
    "for i, file in enumerate(data):\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start\n",
    "    filepath = os.path.join(target_dir, file)\n",
    "    content = load_comments(filepath)\n",
    "    if len(content) < 500:\n",
    "        utils.move_dir(filename = file, destination = trash, source = target_dir)\n",
    "    if i + 1 in checkpoints:\n",
    "        print(f\"{checkpoints[i+1] :.0f}% of the videos have been analyzed\\nTime elapsed: {elapsed_time :.2f} seconds\") \n",
    "trash_list = os.listdir(trash)\n",
    "\n",
    "print(f\"<{len(trash_list)}> files moved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = f\"{os.getcwd()}\\\\Data\"\n",
    "\n",
    "data = os.listdir(target_dir)\n",
    "print(f\"This directory contains <{len(data)}> files\")\n",
    "for file in data:\n",
    "    filepath = os.path.join(target_dir, file)\n",
    "    content = load_comments(filepath)\n",
    "    print(len(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have over 500 videos left, each with at least 500 comments. All that's left to do is run the sentiment analysis on each video. This is going to take a lot of time, which means we'll have to do it in batches. 100 videos per batch seems feasible, so let's do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run split_folder__.py \"F:\\Desktop\\Scuola\\Uni\\Y3\\S2\\Thesis\\Project\\Main project\\GetYoutubeComments\\Data\" \n",
    "#Obtained from https://gist.github.com/zupo/5849843"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "target_dir = f\"{os.getcwd()}\\\\Data\\\\Batch_1\"\n",
    "data = os.listdir(target_dir)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally start the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_video import load_comments\n",
    "\n",
    "batch_1 = f\"{os.getcwd()}\\\\Data\\\\Batch_1\"\n",
    "data_1 = os.listdir(batch_1)\n",
    "os.chdir(batch_1)\n",
    "\n",
    "for file in data_1:\n",
    "    if file.startswith(\"analysis_\"): \n",
    "        continue\n",
    "    else:\n",
    "        start = time.time()\n",
    "        filename = f\"{batch_1}\\\\{file}\"\n",
    "        content = load_comments(filename)\n",
    "\n",
    "        with Pool() as p:\n",
    "            tr_comment = p.map(utils.translate, content)\n",
    "\n",
    "        bert_scores = utils.bert_classifier(content)\n",
    "\n",
    "        df_list = []\n",
    "        scores_list = []\n",
    "\n",
    "        with Pool() as p:\n",
    "            analysis1 = p.map(utils.vader_classifier, tr_comment)\n",
    "            analysis2 = p.map(utils.textblob_classifier, tr_comment)\n",
    "            scores_list.append(analysis1)\n",
    "            scores_list.append(analysis2)\n",
    "\n",
    "        for c, v_score, t_score in zip(content, scores_list[0], scores_list[1]):\n",
    "            df_dict = {\n",
    "                \"Comment\": c,\n",
    "                \"Vader score\": v_score,\n",
    "                \"TextBlob score\": t_score,\n",
    "            }\n",
    "            df_list.append(df_dict)\n",
    "\n",
    "        df = pd.DataFrame(df_list)\n",
    "\n",
    "        series_bert = pd.Series(bert_scores)\n",
    "        df[\"BERT score\"] = series_bert\n",
    "\n",
    "        vader_labels = utils.generate_labels(df[\"Vader score\"], \"vader\")\n",
    "        blob_labels = utils.generate_labels(df[\"TextBlob score\"], \"blob\")\n",
    "        bert_labels = utils.generate_labels(df[\"BERT score\"], \"bert\")\n",
    "\n",
    "        vader_labels_series = pd.Series(vader_labels)\n",
    "        blob_labels_series = pd.Series(blob_labels)\n",
    "        bert_labels_series = pd.Series(bert_labels)\n",
    "\n",
    "        df[\"Vader label\"] = vader_labels_series\n",
    "        df[\"TextBlob label\"] = blob_labels_series\n",
    "        df[\"BERT label\"] = bert_labels_series\n",
    "\n",
    "        df = df[\n",
    "            [\n",
    "                \"Comment\",\n",
    "                \"Vader score\",\n",
    "                \"Vader label\",\n",
    "                \"TextBlob score\",\n",
    "                \"TextBlob label\",\n",
    "                \"BERT score\",\n",
    "                \"BERT label\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        end = time.time()\n",
    "        time_taken = end - start\n",
    "        print(f\"Processed file <{file}>\\nTime taken: <{time_taken}> seconds\")\n",
    "        utils.save_analysis(df, file)\n",
    "\n",
    "os.chdir(\"F:\\\\Desktop\\\\Scuola\\\\Uni\\\\Y3\\\\S2\\\\Thesis\\\\Project\\\\Main project\\\\GetYoutubeComments\") # Reset cwd for next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_video import load_comments\n",
    "\n",
    "batch_2 = f\"{os.getcwd()}\\\\Data\\\\Batch_2\"\n",
    "data_2 = os.listdir(batch_2)\n",
    "os.chdir(batch_2)\n",
    "\n",
    "for file in data_2:\n",
    "    if file.startswith(\"analysis_\"): \n",
    "        continue\n",
    "    else:\n",
    "        start = time.time()\n",
    "        filename = f\"{batch_2}\\\\{file}\"\n",
    "        content = load_comments(filename)\n",
    "\n",
    "        with Pool() as p:\n",
    "            tr_comment = p.map(utils.translate, content)\n",
    "\n",
    "        bert_scores = utils.bert_classifier(content)\n",
    "\n",
    "        df_list = []\n",
    "        scores_list = []\n",
    "\n",
    "        with Pool() as p:\n",
    "            analysis1 = p.map(utils.vader_classifier, tr_comment)\n",
    "            analysis2 = p.map(utils.textblob_classifier, tr_comment)\n",
    "            scores_list.append(analysis1)\n",
    "            scores_list.append(analysis2)\n",
    "\n",
    "        for c, v_score, t_score in zip(content, scores_list[0], scores_list[1]):\n",
    "            df_dict = {\n",
    "                \"Comment\": c,\n",
    "                \"Vader score\": v_score,\n",
    "                \"TextBlob score\": t_score,\n",
    "            }\n",
    "            df_list.append(df_dict)\n",
    "\n",
    "        df = pd.DataFrame(df_list)\n",
    "\n",
    "        series_bert = pd.Series(bert_scores)\n",
    "        df[\"BERT score\"] = series_bert\n",
    "\n",
    "        vader_labels = utils.generate_labels(df[\"Vader score\"], \"vader\")\n",
    "        blob_labels = utils.generate_labels(df[\"TextBlob score\"], \"blob\")\n",
    "        bert_labels = utils.generate_labels(df[\"BERT score\"], \"bert\")\n",
    "\n",
    "        vader_labels_series = pd.Series(vader_labels)\n",
    "        blob_labels_series = pd.Series(blob_labels)\n",
    "        bert_labels_series = pd.Series(bert_labels)\n",
    "\n",
    "        df[\"Vader label\"] = vader_labels_series\n",
    "        df[\"TextBlob label\"] = blob_labels_series\n",
    "        df[\"BERT label\"] = bert_labels_series\n",
    "\n",
    "        df = df[\n",
    "            [\n",
    "                \"Comment\",\n",
    "                \"Vader score\",\n",
    "                \"Vader label\",\n",
    "                \"TextBlob score\",\n",
    "                \"TextBlob label\",\n",
    "                \"BERT score\",\n",
    "                \"BERT label\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        end = time.time()\n",
    "        time_taken = end - start\n",
    "        print(f\"Processed file <{file}>\\nTime taken: <{time_taken}> seconds\")\n",
    "        utils.save_analysis(df, file)\n",
    "\n",
    "os.chdir(\"F:\\\\Desktop\\\\Scuola\\\\Uni\\\\Y3\\\\S2\\\\Thesis\\\\Project\\\\Main project\\\\GetYoutubeComments\") # Reset cwd for next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_video import load_comments\n",
    "\n",
    "batch_3 = f\"{os.getcwd()}\\\\Data\\\\Batch_3\"\n",
    "data_3 = os.listdir(batch_3)\n",
    "os.chdir(batch_3)\n",
    "\n",
    "for file in data_3:\n",
    "    if file.startswith(\"analysis_\"): \n",
    "        continue\n",
    "    else:\n",
    "        start = time.time()\n",
    "        filename = f\"{batch_3}\\\\{file}\"\n",
    "        content = load_comments(filename)\n",
    "\n",
    "        with Pool() as p:\n",
    "            tr_comment = p.map(utils.translate, content)\n",
    "\n",
    "        bert_scores = utils.bert_classifier(content)\n",
    "\n",
    "        df_list = []\n",
    "        scores_list = []\n",
    "\n",
    "        with Pool() as p:\n",
    "            analysis1 = p.map(utils.vader_classifier, tr_comment)\n",
    "            analysis2 = p.map(utils.textblob_classifier, tr_comment)\n",
    "            scores_list.append(analysis1)\n",
    "            scores_list.append(analysis2)\n",
    "\n",
    "        for c, v_score, t_score in zip(content, scores_list[0], scores_list[1]):\n",
    "            df_dict = {\n",
    "                \"Comment\": c,\n",
    "                \"Vader score\": v_score,\n",
    "                \"TextBlob score\": t_score,\n",
    "            }\n",
    "            df_list.append(df_dict)\n",
    "\n",
    "        df = pd.DataFrame(df_list)\n",
    "\n",
    "        series_bert = pd.Series(bert_scores)\n",
    "        df[\"BERT score\"] = series_bert\n",
    "\n",
    "        vader_labels = utils.generate_labels(df[\"Vader score\"], \"vader\")\n",
    "        blob_labels = utils.generate_labels(df[\"TextBlob score\"], \"blob\")\n",
    "        bert_labels = utils.generate_labels(df[\"BERT score\"], \"bert\")\n",
    "\n",
    "        vader_labels_series = pd.Series(vader_labels)\n",
    "        blob_labels_series = pd.Series(blob_labels)\n",
    "        bert_labels_series = pd.Series(bert_labels)\n",
    "\n",
    "        df[\"Vader label\"] = vader_labels_series\n",
    "        df[\"TextBlob label\"] = blob_labels_series\n",
    "        df[\"BERT label\"] = bert_labels_series\n",
    "\n",
    "        df = df[\n",
    "            [\n",
    "                \"Comment\",\n",
    "                \"Vader score\",\n",
    "                \"Vader label\",\n",
    "                \"TextBlob score\",\n",
    "                \"TextBlob label\",\n",
    "                \"BERT score\",\n",
    "                \"BERT label\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        end = time.time()\n",
    "        time_taken = end - start\n",
    "        print(f\"Processed file <{file}>\\nTime taken: <{time_taken}> seconds\")\n",
    "        utils.save_analysis(df, file)\n",
    "        time.sleep(1)\n",
    "\n",
    "os.chdir(\"F:\\\\Desktop\\\\Scuola\\\\Uni\\\\Y3\\\\S2\\\\Thesis\\\\Project\\\\Main project\\\\GetYoutubeComments\") # Reset cwd for next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from get_video import load_comments\n",
    "\n",
    "# batch_4 = f\"{os.getcwd()}\\\\Data\\\\Batch_4\"\n",
    "# data_4 = os.listdir(batch_4)\n",
    "\n",
    "# filename = f\"{batch_4}\\\\{data_4[0]}\"\n",
    "# content = load_comments(filename)\n",
    "# print(content[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from get_video import load_comments\n",
    "\n",
    "# batch_5 = f\"{os.getcwd()}\\\\Data\\\\Batch_5\"\n",
    "# data_5 = os.listdir(batch_5)\n",
    "\n",
    "# filename = f\"{batch_5}\\\\{data_5[0]}\"\n",
    "# content = load_comments(filename)\n",
    "# print(content[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from get_video import load_comments\n",
    "\n",
    "# batch_6 = f\"{os.getcwd()}\\\\Data\\\\Batch_6\"\n",
    "# data_6 = os.listdir(batch_6)\n",
    "\n",
    "# filename = f\"{batch_6}\\\\{data_6[0]}\"\n",
    "# content = load_comments(filename)\n",
    "# print(content[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a1d14109658dfc9fc37f7252e7fc4fbbe9f7c5bac9b61d43e9e98742e708099"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
